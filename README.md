# BenchmarkAggregator ğŸš€

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)
[![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/yourusername/benchmarkaggregator/issues)

Comprehensive, fair, and extensible performance comparisons for the AI community.

[View Leaderboard](https://benchmark-aggregator-lvss.vercel.app/) | [Explore Benchmarks](#benchmarks) | [FAQ](#faq)

## ğŸ“Š Model Performance Overview

| Model | Average Score |
|-------|---------------|
| gpt-4o-2024-08-06 | 69.0 |
| claude-3.5-sonnet | 66.2 |
| gpt-4o-mini-2024-07-18 | 62.1 |
| mistral-large | 61.4 |
| llama-3.1-405b-instruct | 59.8 |
| llama-3.1-70b-instruct | 58.4 |
| claude-3-sonnet | 53.2 |
| gpt-3.5-turbo-0125 | 34.8 |

For detailed scores across all benchmarks, visit our [leaderboard](https://benchmark-aggregator-lvss.vercel.app/).

## ğŸŒŸ Features

- ğŸ“Š 100 randomly drawn samples per benchmark (adjustable)
- ğŸ”Œ Trivial integration of new benchmarks and models
- ğŸ“ˆ Holistic performance view through score averaging
- âš–ï¸ Balanced approach to cost and comprehensiveness

## ğŸ† Current Benchmarks

1. MMLU-Pro
2. GPQA-Diamond
3. ChatbotArena
4. MATH-Hard
5. MuSR
6. ARC-Challenge
7. HellaSwag
8. LiveBench
9. MGSM

ğŸ“– [Learn more about each benchmark on our website](https://benchmark-aggregator-lvss.vercel.app/)

## ğŸ¤” FAQ

<details>
<summary>Why not run all questions for each benchmark?</summary>
Cost considerations. Our approach balances evaluation depth with resource constraints.
</details>

<details>
<summary>How are benchmark samples chosen?</summary>
Random selection, ensuring consistency across all model evaluations.
</details>

<details>
<summary>What does (N = x) mean in benchmark headers?</summary>
Total questions in the benchmark. N/A for Chatbot Arena and LiveBench (results fetched externally).
</details>

ğŸ‘‰ [View more FAQs on our website](https://benchmark-aggregator-lvss.vercel.app/)

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

We're grateful to the creators and maintainers of the benchmark datasets used in this project. 

---

<p align="center">
  Made with â¤ï¸ by the AI community
</p>

<p align="center">
  <a href="https://benchmark-aggregator-lvss.vercel.app/">Website</a> â€¢
</p>